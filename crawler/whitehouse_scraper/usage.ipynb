{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-27T03:48:58.568959Z",
     "start_time": "2021-06-27T03:48:58.558960Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from time import gmtime, strftime\n",
    "\n",
    "news_dateformat = '%B %d, %Y'\n",
    "user_dateformat = '%Y-%m-%d'\n",
    "\n",
    "def now():\n",
    "    \"\"\"\n",
    "    Returns\n",
    "    -------\n",
    "    Current time : str\n",
    "        eg: 2018-11-22 13:35:23\n",
    "    \"\"\"\n",
    "    return strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n",
    "\n",
    "def get_soup(url, headers=None):\n",
    "    \"\"\"\n",
    "    Arguments\n",
    "    ---------\n",
    "    url : str\n",
    "        Web page url\n",
    "    headers : dict\n",
    "        Headers for requests. If None, use Mozilla/5.0 as default user-agent\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    soup : bs4.BeautifulSoup\n",
    "        Soup format web page\n",
    "    \"\"\"\n",
    "\n",
    "    if headers is None:\n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36'}\n",
    "    r = requests.get(url, headers=headers)\n",
    "    html = r.text\n",
    "    page = BeautifulSoup(html, 'lxml')\n",
    "    return page\n",
    "\n",
    "doublespace_pattern = re.compile('\\s+')\n",
    "lineseparator_pattern = re.compile('\\n+')\n",
    "\n",
    "def normalize_text(text):\n",
    "    text = text.replace('\\t', ' ')\n",
    "    text = text.replace('\\r', ' ')\n",
    "    text = lineseparator_pattern.sub('\\n', text)\n",
    "    text = doublespace_pattern.sub(' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def strf_to_datetime(strf, form):\n",
    "    return datetime.strptime(strf, form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-27T03:35:08.675835Z",
     "start_time": "2021-06-27T03:35:07.534728Z"
    }
   },
   "outputs": [],
   "source": [
    "from whitehouse_scraper import yield_latest_allnews\n",
    "\n",
    "begin_date = '2019-01-10'\n",
    "max_num = 50\n",
    "sleep = 1.0\n",
    "\n",
    "for i, json_obj in enumerate(yield_latest_allnews(begin_date, max_num, sleep)):\n",
    "    title = json_obj['title']\n",
    "    time = json_obj['time']\n",
    "    print('[{} / {}] ({}) {}'.format(i+1, max_num, time, title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-27T03:49:15.304511Z",
     "start_time": "2021-06-27T03:49:15.296520Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "from dateutil.parser import parse\n",
    "\n",
    "def parse_page(url):\n",
    "    \"\"\"\n",
    "    Argument\n",
    "    --------\n",
    "    url : str\n",
    "        Web page url\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    json_object : dict\n",
    "        JSON format web page contents\n",
    "        It consists with\n",
    "            title : article title\n",
    "            time : article written time\n",
    "            content : text with line separator \\\\n\n",
    "            url : web page url\n",
    "            scrap_time : scrapped time\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        soup = get_soup(url)\n",
    "        title = soup.find('h1', class_ = 'page-title topper__title news').text \n",
    "        title = re.sub('\\n', '' , title, 100)\n",
    "        title = re.sub('\\t', '' , title, 100)\n",
    "        date = soup.find('time', class_='posted-on entry-date published updated').text\n",
    "        date = parse(date).strftime(\"%Y-%m-%d\")\n",
    "        phrases = soup.find('section', class_='body-content').find_all('p')\n",
    "        content = '\\n'.join([p.text.strip() for p in phrases])\n",
    "        content = re.sub('\\n', '' , content, 100)\n",
    "        content = re.sub('\\t', '' , content, 100)\n",
    "        content = re.sub('\\xa0', '' , content, 1000)\n",
    "        \n",
    "        json_object = {\n",
    "            'title' : title,\n",
    "            'date' : date,\n",
    "            'content' : content,\n",
    "            'url' : url,\n",
    "            'scrap_time' : now()\n",
    "        }\n",
    "        return json_object\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('Parsing error from {}'.format(url))\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-27T03:53:33.205889Z",
     "start_time": "2021-06-27T03:53:33.193878Z"
    }
   },
   "outputs": [],
   "source": [
    "patterns = [\n",
    "    re.compile('https://www.whitehouse.gov/briefing-room/[\\w]+')]\n",
    "url_base = 'https://www.whitehouse.gov/briefing-room/page/{}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-27T03:53:40.769252Z",
     "start_time": "2021-06-27T03:53:40.763251Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def is_matched(url):\n",
    "    for pattern in patterns:\n",
    "        if pattern.match(url):\n",
    "            return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-27T03:53:40.934367Z",
     "start_time": "2021-06-27T03:53:40.928370Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def yield_latest_allnews(begin_date, max_num=10, sleep=1.0):\n",
    "    \"\"\"\n",
    "    Artuments\n",
    "    ---------\n",
    "    begin_date : str\n",
    "        eg. 2018-01-01\n",
    "    max_num : int\n",
    "        Maximum number of news to be scraped\n",
    "    sleep : float\n",
    "        Sleep time. Default 1.0 sec\n",
    "\n",
    "    It yields\n",
    "    ---------\n",
    "    news : json object\n",
    "    \"\"\"\n",
    "\n",
    "    for page in range(1, 11):\n",
    "\n",
    "        # check number of scraped news\n",
    "\n",
    "        # get urls\n",
    "        url = url_base.format(page)\n",
    "        soup = get_soup(url)\n",
    "        links = soup.find_all('a', class_ = 'news-item__title')\n",
    "        urls = [i['href'] for i in links]\n",
    "        print(url)\n",
    "        urls = [url for url in urls if is_matched(url)]\n",
    "\n",
    "        # scrap\n",
    "        for url in urls:\n",
    "            print(url)\n",
    "\n",
    "            news_json = parse_page(url)\n",
    "            \n",
    "\n",
    "            # check date\n",
    "            return news_json\n",
    "            time.sleep(sleep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-27T03:53:43.230307Z",
     "start_time": "2021-06-27T03:53:42.869414Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.whitehouse.gov/briefing-room/page/1/\n",
      "https://www.whitehouse.gov/briefing-room/statements-releases/2021/06/26/statement-by-president-joe-biden-on-the-bipartisan-infrastructure-framework/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'title': 'Statement by President Joe Biden on the Bipartisan Infrastructure Framework',\n",
       " 'date': '2021-06-26',\n",
       " 'content': 'On Thursday, I reached a historic agreement with a bipartisan group of Senators on a $1.2 trillion plan to transform our physical infrastructure.The plan would make the largest investment in infrastructure in history, the biggest investment in rail since the creation of Amtrak, and the largest investment in transit ever.It would fix roads and bridges, make critical investments in our clean energy future, and help this country compete with China and other economic rivals.It would replace lead water pipes in our schools and houses, and connect every American to high-speed internet.It would create millions of high-paying jobs that could not be outsourced.In the days since, the primary focus in Washington has not been about the Plan’s scope, scale or provisions—but rather, how it relates to other legislation before Congress:my American Families Plan.The American Families Plan—which would make historic investments in education, health care, child care, and tax cuts for families,coupled withother investments in care for our seniors, housing, and clean energy—hasbroad support with the American people, but not among Republicans in Congress.Ihave been clear from the start that it was my hope that the infrastructure plan could be one that Democrats and Republicans would work on together, while I would seek to pass my Families Plan and other provisions through the process known as reconciliation.There has been no doubt or ambiguity about my intention to proceed this way.At a press conference after announcing the bipartisan agreement, I indicated that I would refuse to sign the infrastructure bill if it was sent to me without my Families Plan and other priorities, including clean energy. That statement understandably upset some Republicans, who do not see the two plans as linked; they are hoping to defeat my Families Plan—and do not want their support for the infrastructure plan to be seen as aiding passage of the Families Plan.My comments also created the impression that I was issuing a veto threat on the very plan I had just agreed to, which was certainly not my intent.So to be clear: our bipartisan agreement does not preclude Republicans from attempting to defeat my Families Plan; likewise, they should have no objections to my devoted efforts to pass that Families Plan and other proposals in tandem.We will let the American people—and the Congress—decide.The bottom line is this:I gave my word to support the Infrastructure Plan, and that’s what I intend to do.I intend to pursue the passage of that plan, which Democrats and Republicans agreed to on Thursday, with vigor.It would be good for the economy, good for our country, good for our people.I fully stand behind it without reservation or hesitation.Some other Democrats have said they might oppose the Infrastructure Plan because it omits items they think are important:that is a mistake, in my view.Some Republicans now say that they might oppose the infrastructure plan because I am also trying to pass the American Families Plan: that is also a mistake, in my view.I intend to work hard to get both of them passed, because our country needs both—and I ran a winning campaign for President that promised to deliver on both.No one should be surprised that that is precisely what I am doing.I will ask Leader Schumer to schedule both the infrastructure plan and the reconciliation bill for action in the Senate.I expect both to go to the House, where I will work with Speaker Pelosi on the path forward after Senate action.Ultimately, I am confident that Congress will get both to my desk, so I can sign each bill promptly.###',\n",
       " 'url': 'https://www.whitehouse.gov/briefing-room/statements-releases/2021/06/26/statement-by-president-joe-biden-on-the-bipartisan-infrastructure-framework/',\n",
       " 'scrap_time': '2021-06-27 03:53:43'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yield_latest_allnews('2021-06-01', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-27T03:52:38.816082Z",
     "start_time": "2021-06-27T03:52:38.802089Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'urls' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-fb1399676fab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0murls\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'urls' is not defined"
     ]
    }
   ],
   "source": [
    "urls"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
