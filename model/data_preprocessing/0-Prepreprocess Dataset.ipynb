{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmlab/tensorflow/lib/python3.7/site-packages/pandas/compat/__init__.py:120: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk import tokenize\n",
    "from tqdm import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. content meta information\n",
    "    - date, scrap_time, scraping_date, time, author, description, headline, subtitle\n",
    "    - master_id, master_news_id, url, source\n",
    "2. aws mturk label information\n",
    "    - `mturk`: 0 or 1\n",
    "    - `coder.number`: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
    "    - `n_of_labels`: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
    "    - survey_date\n",
    "    - country1, country2, list_of_countries_answered\n",
    "3. columns for training\n",
    "    - labelled, sentiment, sentiment.average, sentence_ner\n",
    "    - grouped, entity_check, entity_validity\n",
    "    - input.text.clean, input_text, title, category, content, lowercase_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20788, 34)\n",
      "Index(['X1', 'master_id', 'master_news_id', 'url', 'source', 'country1',\n",
      "       'country2', 'list_of_countries_answered', 'date', 'input_text', 'mturk',\n",
      "       'survey_date', 'labelled', 'sentiment', 'n_of_labels', 'grouped',\n",
      "       'entity_check', 'title', 'subtitle', 'content', 'category',\n",
      "       'lowercase_content', 'sentence_ner', 'scrap_time', 'scraping_date',\n",
      "       'time', 'author', 'description', 'headline', 'entity_validity',\n",
      "       'sentiment.average', 'coder.number', 'train', 'input.text.clean'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmlab/tensorflow/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('data/peaceindexChallenge_clean_train.csv', encoding='utf-8')\n",
    "print(train_df.shape)\n",
    "print(train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8905, 34)\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('data/peaceindexChallenge_clean_test.csv', encoding='utf-8')\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X1                                0\n",
       "master_id                         0\n",
       "master_news_id                    0\n",
       "url                               1\n",
       "source                          405\n",
       "country1                          0\n",
       "country2                          0\n",
       "list_of_countries_answered     5166\n",
       "date                              0\n",
       "input_text                        0\n",
       "mturk                             0\n",
       "survey_date                     405\n",
       "labelled                          0\n",
       "sentiment                        42\n",
       "n_of_labels                       0\n",
       "grouped                         405\n",
       "entity_check                    405\n",
       "title                             0\n",
       "subtitle                      14074\n",
       "content                         405\n",
       "category                         62\n",
       "lowercase_content               405\n",
       "sentence_ner                    863\n",
       "scrap_time                    12334\n",
       "scraping_date                 19102\n",
       "time                          20043\n",
       "author                        16442\n",
       "description                   19685\n",
       "headline                      19685\n",
       "entity_validity                5166\n",
       "sentiment.average                 0\n",
       "coder.number                      0\n",
       "train                             0\n",
       "input.text.clean                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(df):\n",
    "    data_list = []\n",
    "    for idx, row in tqdm(df[['master_news_id','input_text', 'sentiment.average']].iterrows()):\n",
    "        sent_list = tokenize.sent_tokenize(row['input_text'])\n",
    "        news_id = row['master_news_id']        \n",
    "        sentiment = -1 if row['sentiment.average'] < 0 else 1 if row['sentiment.average'] > 0 else 0\n",
    "\n",
    "        for sent in sent_list:\n",
    "            data_list.append((news_id, sent, sentiment))\n",
    "\n",
    "    final_df = pd.DataFrame(data_list, columns=['id','sentence','sentiment'])\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset for irrelevance and sentiment\n",
    "def create_dataset(raw_df, tag='irrelevant'):\n",
    "    new_df = raw_df.dropna(how='any')\n",
    "\n",
    "    if tag == 'irrelevant':\n",
    "        new_df['sentiment'] = new_df['sentiment'].map({-1: 1, 0: 0, 1: 1})\n",
    "        \n",
    "    elif tag == 'sentiment':\n",
    "        new_df = new_df[new_df.sentiment != 0]\n",
    "        new_df.loc[new_df['sentiment'] < 0, 'sentiment'] = 0\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20788it [00:03, 5850.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20788, 34) (50342, 3)\n",
      "(50342, 3) [1 0]\n",
      "(41109, 3) [0 1]\n"
     ]
    }
   ],
   "source": [
    "# Train Set\n",
    "raw_df = preprocess_dataset(train_df)\n",
    "print(train_df.shape, raw_df.shape)\n",
    "\n",
    "irre_df = create_dataset(raw_df, tag='irrelevant')\n",
    "sent_df = create_dataset(raw_df, tag='sentiment')\n",
    "\n",
    "print(irre_df.shape, irre_df['sentiment'].unique())\n",
    "print(sent_df.shape, sent_df['sentiment'].unique())\n",
    "\n",
    "irre_df.to_csv('data/irrelevant_train.tsv', sep='\\t')\n",
    "sent_df.to_csv('data/sentiment_train.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8905it [00:01, 5954.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8905, 34) (21473, 3)\n",
      "(21473, 3) [1 0]\n",
      "(17628, 3) [0 1]\n"
     ]
    }
   ],
   "source": [
    "# Test Set\n",
    "raw_df = preprocess_dataset(test_df)\n",
    "print(test_df.shape, raw_df.shape)\n",
    "\n",
    "irre_df = create_dataset(raw_df, tag='irrelevant')\n",
    "sent_df = create_dataset(raw_df, tag='sentiment')\n",
    "\n",
    "print(irre_df.shape, irre_df['sentiment'].unique())\n",
    "print(sent_df.shape, sent_df['sentiment'].unique())\n",
    "\n",
    "irre_df.to_csv('data/irrelevant_test.tsv', sep='\\t')\n",
    "sent_df.to_csv('data/sentiment_test.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
